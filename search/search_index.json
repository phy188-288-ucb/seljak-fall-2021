{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"University of California, Berkeley, Department of Physics Bayesian Data Analysis and Machine Learning for Physical Sciences Past Assignments HW1 (Intro to Statistics) : Physics 188 / Physics 288 / Solution HW2 (Intro to Data Analysis, Dimensionality Reduction, and Clustering) : Physics 188 / Physics 288 / Solution HW3 (Linear Algebra - Gaussian Elimination, SVD, Polynomial Regression, PCA, KNN, and Data Modeling) : Physics 188 / Physics 288 / Solution HW4 (Fisher Information Matrix & Independent Component Analysis) : Physics 188 / Physics 288 / Solution Project1-Part1 (Planck analysis I - Linear Algebra & Optimization) : Physics 188 / Physics 288 / Solution Project1-Part2 (Planck analysis II - Bayesfast & Markov Chain Monte Carlo) : Physics 188 / Physics 288 / Solution HW5 (Markov Chain Simulation and Hierarchical Model) : Physics 188 / Physics 288 / Solution HW6 (MLE, MCMC, Distributional Approximation, Expectation Maximization (EM)) : Physics 188 / Physics 288 / Solution HW7 (VI, EL2O, Generative Models, Multimodal Posteriors, and Bayesian Evidence) : Physics 188 / Physics 288 / Solution Project 2 (LIGO analysis - Fourier methods, Matched Filtering, and Differential Equations) : Physics 188 / Physics 288 / Solution HW8 (Interpolation, Resampling Methods, and Gaussian Processes) : Physics 188 / Physics 288 / Solution HW9 (Linear Regression, Regularization, and Logistic & Softmax Regression) : Physics 188 / Physics 288 / Solution Project 3 (Final) (Classification and inference with machine learning) : Physics 188 / Physics 288 / Solution","title":"Home"},{"location":"#bayesian-data-analysis-and-machine-learning-for-physical-sciences","text":"","title":"Bayesian Data Analysis and Machine Learning for Physical Sciences"},{"location":"#past-assignments","text":"HW1 (Intro to Statistics) : Physics 188 / Physics 288 / Solution HW2 (Intro to Data Analysis, Dimensionality Reduction, and Clustering) : Physics 188 / Physics 288 / Solution HW3 (Linear Algebra - Gaussian Elimination, SVD, Polynomial Regression, PCA, KNN, and Data Modeling) : Physics 188 / Physics 288 / Solution HW4 (Fisher Information Matrix & Independent Component Analysis) : Physics 188 / Physics 288 / Solution Project1-Part1 (Planck analysis I - Linear Algebra & Optimization) : Physics 188 / Physics 288 / Solution Project1-Part2 (Planck analysis II - Bayesfast & Markov Chain Monte Carlo) : Physics 188 / Physics 288 / Solution HW5 (Markov Chain Simulation and Hierarchical Model) : Physics 188 / Physics 288 / Solution HW6 (MLE, MCMC, Distributional Approximation, Expectation Maximization (EM)) : Physics 188 / Physics 288 / Solution HW7 (VI, EL2O, Generative Models, Multimodal Posteriors, and Bayesian Evidence) : Physics 188 / Physics 288 / Solution Project 2 (LIGO analysis - Fourier methods, Matched Filtering, and Differential Equations) : Physics 188 / Physics 288 / Solution HW8 (Interpolation, Resampling Methods, and Gaussian Processes) : Physics 188 / Physics 288 / Solution HW9 (Linear Regression, Regularization, and Logistic & Softmax Regression) : Physics 188 / Physics 288 / Solution Project 3 (Final) (Classification and inference with machine learning) : Physics 188 / Physics 288 / Solution","title":"Past Assignments"},{"location":"homeworks/","text":"Homeworks This page contains a list of links to PHY188/288 homeworks. You can also access assignments from a link posted on the bCourses website, under \u201cAssignments\", which contains the most updated information. Past Assignments HW1 (Numerical Integration and ODE/PDEs) : Physics 188 / Physics 288 HW2 (Intro to Statistics) : Physics 188 / Physics 288 HW3 (Intro to Data Analysis, Dimensionality Reduction, and Clustering) : Physics 188 / Physics 288 HW4 (Linear Algebra - Gaussian Elimination, SVD, Polynomial Regression, PCA, KNN, and Data Modeling) : Physics 188 / Physics 288 HW5 (Fisher Information Matrix & Independent Component Analysis) : Physics 188 / Physics 288 Project1-Part1 (Planck analysis I - Linear Algebra & Optimization) : Physics 188 / Physics 288 Project1-Part2 (Planck analysis II - Bayesfast & Markov Chain Monte Carlo) : Physics 188 / Physics 288 HW6 (Markov Chain Simulation and Hierarchical Model) : Physics 188 / Physics 288 HW7 (Distributional Approximation, Expectation Maximization (EM), Interpolation and Resampling Methods) : Physics 188 / Physics 288 HW8 part 1 (VI, EL2O, Generative Models, Multimodal Posteriors, and Gaussian Processes) : Physics 188 / Physics 288 Project 2 (LIGO analysis - Fourier methods, Matched Filtering, and Differential Equations) : Physics 188 / Physics 288 HW8 part 2 (Linear Regression, Regularization, and Logistic & Softmax Regression) : Physics 188 / Physics 288 Project 3 (Final) (Classification and inference with machine learning) : Physics 188 / Physics 288 Instructions For the remainder of the semester, you are going to be writing and running the homeworks remotely on Google Colaboratory. The greatest advantage of using Colab is that it supports free GPU, and this will be particularly useful for future assignments. First, make sure that you are logged in to your Google Drive account. Open https://colab.research.google.com, and you can go over the Colab introduction notebook. Go to your personal google drive and create a folder for this class. Important: Name it as \"P188_288\" On bcourses (under \"Assignments\"), you will be given a link to a zip file containing Jupyter notebooks. Upzip it and upload the entire assignment folder to your Drive folder \"P188_288\". Next, find the assignment notebook (files ending in .ipynb) and double click on it. Open with Colab. CAUTION: Make sure to save your work progress. Note that the Colab will disconnect if you are idle for a certain amount of time or if your total connection time exceeds the max allowed time. If that happens, any unsaved progress will be lost. Hence, please get in the habit of saving your code frequently (File -> Save). Once you finish your homework, you are going to submit the following: Jupyter notebook converted to a pdf file Publicly accessible link to your notebook First, download your notebook as a pdf file. (File > Print > Save as PDF) Important: Before you download your notebook, make sure to display full outputs in Jupyter. Check if your pdf file displays both codes and outputs. To get a publicly accessible link, hit the Share button at the top right, then click \"Get link.\" Make sure that your link is publicly available. (Click on \"Anyone with the link\") Copy link. Go to bcourses and click the corresponding assignment title. Next, click the Submit Assignment button. Click the Choose File button to upload a notebook (pdf file) from your computer. Provide a link to your Colab notebook. click the Submit Assignment button, and make sure to view the confirmation of your submission. <!-- Past Assignments: To download a Jupyter notebook, right click the link and save it as an .ipynb file. <!-- - HW1 (Numerical Integration and ODE/PDEs): PDF / Jupyter notebook <!-- - HW2 (Intro to Statistics): PDF / Jupyter notebook <!-- - HW3 (Intro to Statistics - Part 2): PDF / Jupyter notebook <!-- - HW4 (Linear Algebra and Data Modeling): PDF / Jupyter notebook <!-- - HW5 (Markov Chain Simulation and Hierarchical Model): PDF / Jupyter notebook <!-- - Project 1 - part 1 (Fisher Information Matrix): PDF / Jupyter notebook <!-- - Project 1 - part 2 (Linear Algebra and Optimization): PDF / Jupyter notebook <!-- - Project 1 - part 1 (Markov chain Monte Carlo): PDF / Jupyter notebook <!-- - HW6 (MLE, MCMC, Interpolation, Expectation Maximization (EM), and Resampling Methods): PDF / Jupyter notebook <!-- - HW7 (Distributional Approximation and Gaussian Processes): PDF / Jupyter notebook <!-- - Project 2 (Fourier methods, Matched Filtering, and Differential Equations): PDF / Jupyter notebook <!-- - HW8 (Linear Regression, Regularization, and Logistic & Softmax Regression): PDF / Jupyter notebook <!-- - Project 3 (Classification and inference with machine learning): PDF / Jupyter notebook","title":"Homeworks"},{"location":"homeworks/#homeworks","text":"This page contains a list of links to PHY188/288 homeworks. You can also access assignments from a link posted on the bCourses website, under \u201cAssignments\", which contains the most updated information.","title":"Homeworks"},{"location":"homeworks/#past-assignments","text":"HW1 (Numerical Integration and ODE/PDEs) : Physics 188 / Physics 288 HW2 (Intro to Statistics) : Physics 188 / Physics 288 HW3 (Intro to Data Analysis, Dimensionality Reduction, and Clustering) : Physics 188 / Physics 288 HW4 (Linear Algebra - Gaussian Elimination, SVD, Polynomial Regression, PCA, KNN, and Data Modeling) : Physics 188 / Physics 288 HW5 (Fisher Information Matrix & Independent Component Analysis) : Physics 188 / Physics 288 Project1-Part1 (Planck analysis I - Linear Algebra & Optimization) : Physics 188 / Physics 288 Project1-Part2 (Planck analysis II - Bayesfast & Markov Chain Monte Carlo) : Physics 188 / Physics 288 HW6 (Markov Chain Simulation and Hierarchical Model) : Physics 188 / Physics 288 HW7 (Distributional Approximation, Expectation Maximization (EM), Interpolation and Resampling Methods) : Physics 188 / Physics 288 HW8 part 1 (VI, EL2O, Generative Models, Multimodal Posteriors, and Gaussian Processes) : Physics 188 / Physics 288 Project 2 (LIGO analysis - Fourier methods, Matched Filtering, and Differential Equations) : Physics 188 / Physics 288 HW8 part 2 (Linear Regression, Regularization, and Logistic & Softmax Regression) : Physics 188 / Physics 288 Project 3 (Final) (Classification and inference with machine learning) : Physics 188 / Physics 288","title":"Past Assignments"},{"location":"homeworks/#instructions","text":"For the remainder of the semester, you are going to be writing and running the homeworks remotely on Google Colaboratory. The greatest advantage of using Colab is that it supports free GPU, and this will be particularly useful for future assignments. First, make sure that you are logged in to your Google Drive account. Open https://colab.research.google.com, and you can go over the Colab introduction notebook. Go to your personal google drive and create a folder for this class. Important: Name it as \"P188_288\" On bcourses (under \"Assignments\"), you will be given a link to a zip file containing Jupyter notebooks. Upzip it and upload the entire assignment folder to your Drive folder \"P188_288\". Next, find the assignment notebook (files ending in .ipynb) and double click on it. Open with Colab. CAUTION: Make sure to save your work progress. Note that the Colab will disconnect if you are idle for a certain amount of time or if your total connection time exceeds the max allowed time. If that happens, any unsaved progress will be lost. Hence, please get in the habit of saving your code frequently (File -> Save). Once you finish your homework, you are going to submit the following: Jupyter notebook converted to a pdf file Publicly accessible link to your notebook First, download your notebook as a pdf file. (File > Print > Save as PDF) Important: Before you download your notebook, make sure to display full outputs in Jupyter. Check if your pdf file displays both codes and outputs. To get a publicly accessible link, hit the Share button at the top right, then click \"Get link.\" Make sure that your link is publicly available. (Click on \"Anyone with the link\") Copy link. Go to bcourses and click the corresponding assignment title. Next, click the Submit Assignment button. Click the Choose File button to upload a notebook (pdf file) from your computer. Provide a link to your Colab notebook. click the Submit Assignment button, and make sure to view the confirmation of your submission. <!-- Past Assignments: To download a Jupyter notebook, right click the link and save it as an .ipynb file. <!-- - HW1 (Numerical Integration and ODE/PDEs): PDF / Jupyter notebook <!-- - HW2 (Intro to Statistics): PDF / Jupyter notebook <!-- - HW3 (Intro to Statistics - Part 2): PDF / Jupyter notebook <!-- - HW4 (Linear Algebra and Data Modeling): PDF / Jupyter notebook <!-- - HW5 (Markov Chain Simulation and Hierarchical Model): PDF / Jupyter notebook <!-- - Project 1 - part 1 (Fisher Information Matrix): PDF / Jupyter notebook <!-- - Project 1 - part 2 (Linear Algebra and Optimization): PDF / Jupyter notebook <!-- - Project 1 - part 1 (Markov chain Monte Carlo): PDF / Jupyter notebook <!-- - HW6 (MLE, MCMC, Interpolation, Expectation Maximization (EM), and Resampling Methods): PDF / Jupyter notebook <!-- - HW7 (Distributional Approximation and Gaussian Processes): PDF / Jupyter notebook <!-- - Project 2 (Fourier methods, Matched Filtering, and Differential Equations): PDF / Jupyter notebook <!-- - HW8 (Linear Regression, Regularization, and Logistic & Softmax Regression): PDF / Jupyter notebook <!-- - Project 3 (Classification and inference with machine learning): PDF / Jupyter notebook","title":"Instructions"},{"location":"lectures/","text":"Lecture Notes This page contains a list of links to PHY188/288 lecture notes. Lecture 1: Intro to Statistics Lecture 2: Intro to Data Analysis and Machine Learning Lecture 3: Linear Algebra Lecture 4: Information Theory, Entropy, Experiment Design Lecture 5: Nonlinear Equations and Optimization Lecture 6: Monte Carlo Sampling and Integration Lecture 7: Advanced Bayesian Concepts (Probabilistic graphical models, Hierarchical Bayesian models, etc) Lecture 8: Distributional Approximation Lecture 9: Useful Statistical Methods of Data Analysis Lecture 10: From Interpolation to Regressions to Gaussian Processes Lecture 11: Classification Lecture 12: Fourier Methods Lecture 13: Neural Networks for Supervised Learning Lecture 14: Deep Networks for Unsupervised Learning <!-- A full list can be found at on github","title":"Lectures"},{"location":"lectures/#lecture-notes","text":"This page contains a list of links to PHY188/288 lecture notes. Lecture 1: Intro to Statistics Lecture 2: Intro to Data Analysis and Machine Learning Lecture 3: Linear Algebra Lecture 4: Information Theory, Entropy, Experiment Design Lecture 5: Nonlinear Equations and Optimization Lecture 6: Monte Carlo Sampling and Integration Lecture 7: Advanced Bayesian Concepts (Probabilistic graphical models, Hierarchical Bayesian models, etc) Lecture 8: Distributional Approximation Lecture 9: Useful Statistical Methods of Data Analysis Lecture 10: From Interpolation to Regressions to Gaussian Processes Lecture 11: Classification Lecture 12: Fourier Methods Lecture 13: Neural Networks for Supervised Learning Lecture 14: Deep Networks for Unsupervised Learning <!-- A full list can be found at on github","title":"Lecture Notes"}]}